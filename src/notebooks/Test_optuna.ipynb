{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pdb\n",
    "import sys\n",
    "import json\n",
    "import math\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from argparse import Namespace\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn import DataParallel\n",
    "\n",
    "from data.data_loaders import get_detection_dataset\n",
    "import data.data_processing as data_processing\n",
    "import lib.arguments as arguments\n",
    "import lib.model_setup as model_setup\n",
    "import lib.inference as inference\n",
    "import lib.metrics as metrics\n",
    "import lib.loss as loss\n",
    "import lib.utils as utils\n",
    "from lib.logger import Logger, log_function, print_\n",
    "from lib.utils import for_all_methods, load_experiment_parameters\n",
    "from CONFIG import CONFIG\n",
    "\n",
    "from lib.detection_coco_utils import get_coco_api_from_dataset\n",
    "from lib.detection_coco_eval import CocoEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DetectorTrain:\n",
    "    \"\"\"\n",
    "    Class used for training the FasterRCNN model and validating its\n",
    "    performance for the task of person detection in styled data\n",
    "    Args:\n",
    "    -----\n",
    "    exp_path: string\n",
    "        path to the experiment directory\n",
    "    checkpoint: string\n",
    "        name of the checkpoit to load to resume training\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, exp_path, checkpoint=None, dataset_name=None, Lambda_D=None,\n",
    "                 Lambda_P=None, params=None):\n",
    "        \"\"\"\n",
    "        Initializer of the training object\n",
    "        \"\"\"\n",
    "\n",
    "        self.exp_path = exp_path\n",
    "        self.Lambda_D = Lambda_D\n",
    "        self.Lambda_P = Lambda_P\n",
    "        self.params = params\n",
    "        self.models_path = os.path.join(self.exp_path, \"models\", \"detector\")\n",
    "        self.exp_data = load_experiment_parameters(exp_path)\n",
    "\n",
    "        self.checkpoint = checkpoint\n",
    "        if(checkpoint is None):\n",
    "            self.checkpoint_path = None\n",
    "        else:\n",
    "            self.checkpoint_path = os.path.join(self.models_path, self.checkpoint)\n",
    "\n",
    "        if(dataset_name is not None):\n",
    "            self.exp_data[\"dataset\"][\"dataset_name\"] = dataset_name\n",
    "\n",
    "        self.perceptual_loss_dict = loss.load_perceptual_loss_dict(exp_data=self.exp_data,\n",
    "                                                                   params=self.params)\n",
    "\n",
    "        self.pretrained = True\n",
    "        self.cur_epoch = 0\n",
    "        self.num_epochs = 3\n",
    "        self.save_frequency = self.exp_data[\"training\"][\"save_frequency\"]\n",
    "        self.display_frequency = 300\n",
    "        self.class_ids = [1]\n",
    "        self.num_classes = len(self.class_ids)\n",
    "\n",
    "        return\n",
    "\n",
    "\n",
    "    def load_detection_dataset(self):\n",
    "        \"\"\"\n",
    "        Loading training and validation data-loaders. The data used corresponds to\n",
    "        images from the (styled) COCO dataset. We only train for certain object classes,\n",
    "        i.e., we only care about the ids specified by class_ids.\n",
    "        \"\"\"\n",
    "\n",
    "        train_loader,\\\n",
    "        valid_loader  = get_detection_dataset(exp_data=self.exp_data, train=True,\n",
    "                                              validation=True, shuffle_train=True,\n",
    "                                              shuffle_valid=False, class_ids=self.class_ids,\n",
    "                                              perceptual_loss_dict=self.perceptual_loss_dict)\n",
    "\n",
    "        self.train_loader, self.valid_loader = train_loader, valid_loader\n",
    "\n",
    "        self.coco = get_coco_api_from_dataset(self.valid_loader.dataset)\n",
    "        self.iou_types = [\"bbox\"]\n",
    "\n",
    "        return\n",
    "\n",
    "\n",
    "    def load_detector_model(self):\n",
    "        \"\"\"\n",
    "        Loading the pretrained person detector model\n",
    "        \"\"\"\n",
    "\n",
    "        # setting up the device\n",
    "        torch.backends.cudnn.fastest = True\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "        model = model_setup.setup_detector(pretrained=self.pretrained,\n",
    "                                           num_classes=self.num_classes)\n",
    "        model.eval()\n",
    "        self.model = DataParallel(model).to(self.device)\n",
    "\n",
    "        # fitting optimizer and scheduler given exp_data parameters\n",
    "        optimizer, scheduler = model_setup.setup_optimizer(exp_data=self.exp_data,\n",
    "                                                           net=self.model)\n",
    "\n",
    "        lr_factor = self.exp_data[\"training\"][\"learning_rate_factor\"]\n",
    "        patience = self.exp_data[\"training\"][\"patience\"]\n",
    "        # scheduler = torch.optim.lr_scheduler.StepLR(optimizer, gamma=lr_factor,\n",
    "        #                                             step_size=patience, verbose=True)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=patience,\n",
    "                                                               factor=lr_factor, min_lr=1e-8,\n",
    "                                                               mode=\"max\", verbose=True)\n",
    "\n",
    "        self.optimizer, self.scheduler = optimizer, scheduler\n",
    "\n",
    "        # loading pretraining checkpoint if specified\n",
    "        if(self.checkpoint is not None):\n",
    "            print_(f\"Loading checkpoint {self.checkpoint}\")\n",
    "            # for resuming a training on the same dataset\n",
    "            if(self.params.resume_training):\n",
    "                self.model, self.optimizer, self.scheduler, \\\n",
    "                    self.cur_epoch = model_setup.load_checkpoint(self.checkpoint_path,\n",
    "                                                                 model=self.model,\n",
    "                                                                 only_model=False,\n",
    "                                                                 optimizer=self.optimizer,\n",
    "                                                                 scheduler=self.scheduler)\n",
    "                print_(f\"Resuming training from epoch {self.cur_epoch}/{self.num_epochs}.\")\n",
    "            # for fine-tuning on a new dataset\n",
    "            else:\n",
    "                self.model = model_setup.load_checkpoint(self.checkpoint_path,\n",
    "                                                         model=self.model,\n",
    "                                                         only_model=True,\n",
    "                                                         drop_head=True)\n",
    "        return\n",
    "\n",
    "\n",
    "    def training_loop(self):\n",
    "        \"\"\"\n",
    "        Iteratively executing training and validation epochs while saving loss value\n",
    "        in training logs file\n",
    "        \"\"\"\n",
    "\n",
    "        self.model = self.model.to(self.device)\n",
    "\n",
    "        # iterating for the desired number of epochs\n",
    "        for epoch in range(self.cur_epoch, self.num_epochs):\n",
    "            print_(f\"########## Epoch {epoch+1}/{self.num_epochs} ##########\")\n",
    "            self.model.eval()\n",
    "            self.validation_epoch()\n",
    "            self.model.train()\n",
    "            self.train_epoch()\n",
    "            if(self.scheduler is not None):\n",
    "                self.scheduler.step(self.valid_ap)\n",
    "\n",
    "        print_(f\"Finished training procedure\")\n",
    "\n",
    "        return self.valid_ap\n",
    "\n",
    "\n",
    "    def train_epoch(self):\n",
    "        \"\"\"\n",
    "        Computing a training epoch: forward and backward pass for the complete training set\n",
    "        \"\"\"\n",
    "\n",
    "        train_loss = []\n",
    "        for i_batch, (imgs, metas_) in enumerate(tqdm(self.train_loader)):\n",
    "\n",
    "            imgs = torch.stack(imgs)\n",
    "            metas = [{k: v for k, v in t.items()} for t in metas_]\n",
    "\n",
    "            # preparing annotations for forward pass\n",
    "            imgs = imgs.to(self.device).float()\n",
    "            \n",
    "            batch_perceptual_loss = []\n",
    "            targets = []\n",
    "            for i, meta in enumerate(metas):\n",
    "                d = {}\n",
    "                d[\"boxes\"] = meta[\"targets\"][\"boxes\"].to(self.device).float()\n",
    "                d[\"labels\"] = meta[\"targets\"][\"labels\"].to(self.device).long()\n",
    "                targets.append(d)   \n",
    "                batch_perceptual_loss.append(float(meta[\"perceptual_loss\"]))\n",
    "            \n",
    "            # Average batch_perceptual_loss\n",
    "            avg_batch_perceptual_loss = np.average(np.array(batch_perceptual_loss))\n",
    "            \n",
    "            # forward pass and loss computation\n",
    "            loss_dict = self.model(imgs / 255, targets)  # important to divide by 255\n",
    "\n",
    "            loss = sum(loss for loss in loss_dict.values())\n",
    "            loss_value = loss.item()\n",
    "            if loss_value == 0 or not math.isfinite(loss_value):\n",
    "                print_(f\"Loss is {loss_value}, skipping image\")\n",
    "                continue\n",
    "\n",
    "            ### Adding the perceptual loss here?\n",
    "            if(self.exp_data[\"dataset\"][\"dataset_name\"]) == 'styled_coco' and self.params.use_perceptual_loss:\n",
    "                loss_value = self.Lambda_D * loss_value + self.Lambda_P * avg_batch_perceptual_loss\n",
    "\n",
    "            train_loss.append(loss_value)\n",
    "\n",
    "            # printing small update every few mini-batches\n",
    "            if(i % self.display_frequency == 0 and self.display_frequency > 0):\n",
    "                print_(f\"    Batch {i}/{len(self.train_loader)}\")\n",
    "                print_(f\"        Loss: {np.mean(train_loss)}\")\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            if i_batch >= 5:\n",
    "                print (\"Breaking here for mini-subset training\")\n",
    "                break\n",
    "\n",
    "        self.train_loss = np.mean(train_loss)\n",
    "        print_(f\" Train Loss: {self.train_loss}\")\n",
    "\n",
    "        return\n",
    "\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def validation_epoch(self):\n",
    "        \"\"\"\n",
    "        Computing a validation epoch: forward pass for regressing the bbox positions\n",
    "        and classifying bbox content\n",
    "        \"\"\"\n",
    "\n",
    "        self.coco_evaluator = CocoEvaluator(self.coco, self.iou_types)\n",
    "\n",
    "        for i, (imgs, metas_) in enumerate(tqdm(self.valid_loader)):\n",
    "            imgs = torch.stack(imgs)\n",
    "            metas = [{k: v for k, v in t.items()} for t in metas_]\n",
    "            # validation only on 1/5th of the images to avoid overfitting\n",
    "            if(i >= len(self.valid_loader) // 5):\n",
    "                break\n",
    "\n",
    "            # prediciting bounding boxes\n",
    "            imgs = imgs.to(self.device).float()\n",
    "            outputs = self.model(imgs / 255)\n",
    "\n",
    "            # mapping image ids with annotatons and outputs\n",
    "            outputs = [{k: v.cpu() for k, v in t.items()} for t in outputs]\n",
    "            res = {meta[\"image_id\"]: output for meta, output in zip(metas, outputs)}\n",
    "\n",
    "            # updating evaluation object\n",
    "            self.coco_evaluator.update(res)\n",
    "            \n",
    "            if i >= 5:\n",
    "                print (\"Breaking here for mini sub-set evaluation\")\n",
    "                break\n",
    "\n",
    "        # accumulate predictions from all images and computing evaluation metric\n",
    "        self.coco_evaluator.synchronize_between_processes()\n",
    "        self.coco_evaluator.accumulate()\n",
    "        self.valid_stats = self.coco_evaluator.summarize()[\"bbox\"].tolist()\n",
    "        self.valid_ap = self.valid_stats[0]\n",
    "\n",
    "        stats_names = ['AP', 'Ap .5', 'AP .75', 'AP (M)', 'AP (L)', 'AR', 'AR .5',\n",
    "                       'AR .75', 'AR (M)', 'AR (L)']\n",
    "        print_(\"Validation Stats\")\n",
    "        print_(f\"{stats_names}\")\n",
    "        print_(f\"{self.valid_stats}\")\n",
    "\n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "def objective(trial):\n",
    "    print(\"Optimize Start\")    \n",
    "    \n",
    "    #number of the unit\n",
    "    Lambda_D = trial.suggest_uniform(\"Lambda_D\", 0, 1)\n",
    "    Lambda_P = trial.suggest_uniform(\"Lambda_P\", 0, 1)\n",
    "    \n",
    "    exp_path = \"styled_coco_redblackcombined_alpha_05/experiment_2020-11-02_21-59-12\"\n",
    "    exp_path = os.path.join(CONFIG[\"paths\"][\"experiments_path\"], exp_path)\n",
    "    checkpoint = None\n",
    "    dataset_name = \"styled_coco\"\n",
    "    params = {\n",
    "        \"save\": False,\n",
    "        \"resume_training\": False,\n",
    "        \"use_perceptual_loss\": True\n",
    "    }\n",
    "    params = Namespace(**params)\n",
    "    \n",
    "    trainer = DetectorTrain(exp_path=exp_path, checkpoint=checkpoint,\n",
    "                            dataset_name=dataset_name, Lambda_D=Lambda_D, \n",
    "                            Lambda_P=Lambda_P, params=params)\n",
    " \n",
    "\n",
    "    trainer.load_detection_dataset()\n",
    "    trainer.load_detector_model()\n",
    "    valid_ap = trainer.training_loop()\n",
    "    \n",
    "    return valid_ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pickle\n",
    "timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "study_name = 'object_detection_' + timestr + '.pkl'\n",
    "study_path = os.path.join('/localhome/ronak/efi/code/EnhancePoseEstimation/lambda_study', study_name)\n",
    "with open(study_path, 'wb') as out:\n",
    "    pickle.dump(study, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trial = study.best_trial\n",
    "# for key, value in trial.params.items():\n",
    "#     print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
